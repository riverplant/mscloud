1. 傳統: 分佈式基於發佈/訂閲模式的消息隊列(Message Queue)，主要應用數據實時處理領域

        将发布的消息分为不同的类别，订阅之只接收感兴趣的消息

2. 最新： 開源的分佈式事件流平台(Event Stream Platform)

   消息隊列模式: 
   
      點對點: Message Queue,消費者消費數據之後刪除消息
   
   
   
      發佈/訂閲(使用最多): Message Queue的 Topic,
        可以有多個topic主題
        消費者消費數據之後不刪除消息
        每個消費者互相獨立，都可以消費到數據
-----------------------------------------------------------------------------------
KafKa基礎架構:
   1. Producer: 对接外部传入的数据
   
   
   2. Topic：分成多個partition[分區進行存儲，可以提高吞吐量]
            broker0(代表一個服務器101):  TopicA-Partition0
            broker1(代表一個服務器102):  TopicA-Partition1
            broker2(代表一個服務器103):  TopicA-Partition2
            
            消費者可以選擇不同的分區來進行消費
            但是需要注意:！！！一個分區的數據只能由一個消費者來消費!!!!!!!
            
            爲了保障分區的可靠性，每個broker中存儲了若干副本,[生產和消費只能操作leader副本]，
            只有等待leader出問題，follower副本才有可能成為leader被生產者和消費者操作

            Zookeeper记录服务器节点运行的状态(哪个分区在线，哪个分区不在线)，记录每一个分区的Leader信息!!!!!!!!
            
            
   3.Consumer: 一个分区(broker)的数据只能由一个消费者进行消费!!!!!!!!!!!
   
----------------------------------------快速入門------------------------------------
tar -zxvf kafka....  解壓縮
mv kafka_...   kafka  修改名稱
配置jdk:
vim ~/.bashrc

export JAVA_HOME=/opt/module/jkd21
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:"$JAVA_HOME"/lib/tools.jar

source ~/.bashrc

-----------------kafka配置--------------------------
1. 配置server.properties


borker.id=0   //kafka身份唯一表示，集群安裝下，這個id必須唯一

log.dirs=      //日志保存

zookeeper.connect=kafka

设置 Kafka 环境变量

vim ~/.bashrc

# Kafka 安装目录
export KAFKA_HOME=/opt/module/kafka
export PATH=$PATH:$KAFKA_HOME/bin
source ~/.bashrc

kafka-topics.sh --version  查看kafka版本

Kafka 默认使用 config/zookeeper.properties，你需要检查或修改它。
tickTime=2000
initLimit=5
syncLimit=2
dataDir=/opt/module/kafka/data/zookeeper  # 指定 Zookeeper 数据存储路径
clientPort=2181  # 监听客户端连接的端口

tickTime=2000：Zookeeper 服务器与客户端之间的最小心跳时间（单位：ms）。
initLimit=5：Follower 连接到 Leader 允许的初始化时间（tick 数）。
syncLimit=2：Follower 与 Leader 之间允许的最大响应时间（tick 数）。
dataDir：Zookeeper 存储数据的目录（默认是 /tmp/zookeeper，建议修改）。
clientPort=2181：Zookeeper 监听的端口（默认 2181）。

zookeeper-server-start.sh -daemon $KAFKA_HOME/config/zookeeper.properties
ps -ef | grep zookeeper


-----------------編寫啓動或者停止脚本--------------------------------
#!/bin/bash

# 定义 Kafka 服务器列表
KAFKA_NODES=("kafka100")  # 如果是集群模式，可以添加更多节点，如 kafka101, kafka102

# Kafka 安装目录
KAFKA_HOME="/opt/module/kafka"

# 获取当前操作
ACTION=$1

case $ACTION in
"start")
  for NODE in "${KAFKA_NODES[@]}"
  do
    echo "--- 启动 $NODE Kafka ---"
    
    # 检查 Kafka 是否已经在运行
    ssh $NODE "ps -ef | grep kafka.Kafka | grep -v grep"
    
    if [ $? -eq 0 ]; then
      echo "Kafka 已在 $NODE 运行，跳过启动"
    else
      ssh $NODE "$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties"
      echo "Kafka 启动命令已发送到 $NODE"
    fi
  done
;;
"stop")
  for NODE in "${KAFKA_NODES[@]}"
  do
    echo "--- 停止 $NODE Kafka ---"
    
    # 先检查 Kafka 是否正在运行
    ssh $NODE "ps -ef | grep kafka.Kafka | grep -v grep"
    
    if [ $? -eq 0 ]; then
      ssh $NODE "$KAFKA_HOME/bin/kafka-server-stop.sh"
      echo "Kafka 停止命令已发送到 $NODE"
    else
      echo "Kafka 未在 $NODE 运行，无需停止"
    fi
  done
;;
*)
  echo "用法: $0 {start|stop}"
  exit 1
;;
esac

----------------------------------生產者-------------------------------------------
---------------生產者脚本: kafka-console-producer.sh--------------------
----向topic發送數據

bin/kafka-console-producer.sh  --bootstrap-server 【kafka100:9092，kafka101:9092，kafka103:9092】 --topic first

bin/kafka-console-producer.sh  --bootstrap-server kafka100:9092 --topic first

--bootstrap-server 【kafka100:9092，kafka101:9092，kafka103:9092】: 连接kafka
--topic first      指定要操作的topic

 --create --topic test-topic  创建主题
 --delete:   删除主题
 --alter:    修改主题
 --list:     查看所有的主题
 --describe:  查看主题详细信息
 --partitions 1 指定创建的topic有多少个分区(每一个broker0上都可以创建多个分区) 用于提高性能、并发处理 3~10个
 --replication-factor 1  指定创建的topic有多少个副本  不能大于 Kafka broker 数量，一台服务器是一个副本

生产者端:
PS D:\kafka\kafka_2.13-3.7.0\bin\windows> .\kafka-console-producer.bat --bootstrap-server localhost:9092 --topic test-topic

消费者端:
PS D:\kafka\kafka_2.13-3.7.0\bin\windows> .\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic test-topic --from-beginning



1. main 綫程創建一個Producer 

                      --- send(ProducerRecord)---> 攔截器Interceptors(對數據進行加工)
                      
                      ------->Serializer(序列化器)
                      
                      -------->分區器(Partitioner)通過發往不同的緩存隊列來實現(隊列大小32m)[DQuene1,DQuene2,DQuene3.....]
                      每一个分区会创建一个队列
                      
                       -------->ProducerBatch(16K)
                       儅數據纍計到batch.size的時候，才會發送
                       【linger.ms:如果數據一直沒有達到batch.size，sender等待linger.ms的時間就會發送】 
                       batch.size:
                       linger.ms:

                       ----sender綫程----> Sender(讀取數據)
                       
                       如果發送出去的消息一直得不到Broker應答，儅積纍到5個消息的時候將停止發送
                       -----NetworkClient【Request1, Request2.....】-----
                       
                       
                       ------------>Selector(打通輸入流和輸出流)
                       
                       
                       ------------->Broker【分區1，分區2....】
                       應答acks:
                       0: 生產者發送過來的數據，不需要等數據落盤就應答
                       1： 生產者發送過來的數據，Leader收到數據後應答
                      -1(all): Leader和ISR隊列所有節點收齊數據后才應答


生產者分區:  每一個Partition在一個Broker上存儲，可以把海量的數據按照分區
           切割成一塊塊數據存儲在多台Broker上，實現負載均衡的效果
           
DefaultPartitioner: Kafka默認分區器

1. 如果指定了分區，就按照指定分區發送

public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value) {
        this(topic, partition, timestamp, key, value, null);
    }

    /**
     * Creates a record to be sent to a specified topic and partition
     *
     * @param topic The topic the record will be appended to
     * @param partition The partition to which the record should be sent
     * @param key The key that will be included in the record
     * @param value The record contents
     * @param headers The headers that will be included in the record
     */
    public ProducerRecord(String topic, Integer partition, K key, V value, Iterable<Header> headers) {
        this(topic, partition, null, key, value, headers);
    }

    /**
     * Creates a record to be sent to a specified topic and partition
     *
     * @param topic The topic the record will be appended to
     * @param partition The partition to which the record should be sent
     * @param key The key that will be included in the record
     * @param value The record contents
     */
    public ProducerRecord(String topic, Integer partition, K key, V value) {
        this(topic, partition, null, key, value, null);
    }

     2. 如果沒有指定分區，但是指定了Key, 就按照（ key的hash值%分區數 ）相同的 key 总是映射到相同的分区
     例如key1 的hash值=5, key2 的hash值=6,  topic 的 partition = 2
     key1对应的value1写入 5 % 2 = 1号分区
     key2对应的value1写入0号分区

     在生产环境中，如果希望将订单表中的数据发送到kafka同一个分区，可以用表名来做key
    /**
     * Create a record to be sent to Kafka
     *
     * @param topic The topic the record will be appended to
     * @param key The key that will be included in the record
     * @param value The record contents
     */
    public ProducerRecord(String topic, K key, V value) {
        this(topic, null, null, key, value, null);
    }

    3. 如果沒有指定分區，沒有指定Key，就将一批消息粘性地发送到同一个分区StickyPartitioner，
    直到 batch(16k) 被填满或者达到超时阈值(linger.ms)，然后才会切换到新的分区
    /**
     * Create a record with no key
     *
     * @param topic The topic this record should be sent to
     * @param value The record contents
     */
    public ProducerRecord(String topic, V value) {
        this(topic, null, null, null, value, null);
    }


/*********************************自定义分区器*********************************************************/
如果发送过来的数据中包括river,发往0号分区，如果不包括，发往1号分区

    

業務需求：
  將訂單表中的所有數據發送到kafka某一個分區: 將key設置爲訂單表的名字

  通過kafka的分區器實現，將發送過來的數據中如果包含nitere的數據都發往0號分區，其它發往1號分區
/*********************************************************************************************/


----生產者提高吞吐量:linger.ms: 默認爲0ms,只要有消息就立刻發送

修改 batch.size： 批次大小，默認16k
    linger.ms: 等待時間，修改為5-100ms(影响数据延时)
    compression.tye: 壓縮snappy
    RecordAccumulator: 緩衝區大小，修改爲64m

/*********************************************************************************************/

-----數據可靠性(应答策略): ACK :
               0,
               1, (一般用於傳輸普通的日志)
               all(-1) 傳輸和錢相關的數據，必須保證
【非常重要!!!】
數據完全可靠條件: ACK=-1 
             + 分區副本>=2（leader + follower） 
             + ISR(in-sync replica set)裏應答的最小副本數>=2
             有可能出現重複數據


【非常重要!!!】
至少一次(At Lease Once): ACK=-1 
             + 分區副本>=2（leader + follower） 
             + ISR(in-sync replica set)裏應答的最小副本數>=2
             有可能數據重複
             ISR放的都是和Leader正常通信的breaker, 一旦Follower长时间未向Leader发送通信请求或者同步数据，
             会被踢出ISR!!!!!!
             
最多一次(At Most Once): ACK=0 保證數據不重複，但是可能丟數據

精確一次(Exactly Once): 冪等性和事務!!!!!!!!!!!!!!!

----------冪等性: Producer不論向Broker發送多少次重複數據，Broker只會持久化一次，不會重複

【精確一次(Exactly Once) = 冪等性 】*************************************************
             冪等性
             + 至少一次(At Lease Once): ACK=-1
             + 分區副本>=2（leader + follower）  除了有一个leader之外至少要有一个follower
             + ISR(in-sync replica set)裏應答的最小副本數>=2, 正常通信follower至少有1个
             
冪等性判斷重複數據的標準: 具有<PID,Partition,SeqNumber>相同主鍵的消息提交時
                    Broker指揮持久化一條
                    PID: 生產者ID,每次Kafka重啓都會分配一個新的
                    Partition: 分區號
                    SeqNumber: 單調遞增
                   【 冪等性只能保證單分區單會話中不重複    】
開啓冪等性: 【enable.idempotence】   默認true    

------------生產者事務: 開啓事務，必須先開啓冪等性  

Transaction: 用戶提前設置transactional.id，自定義唯一ID，不受kafka重啓影響

1. 初始化事務:
void initTransactions()

2. 開啓事務
void beginTransaction()


3. 提交事務
void commitTransaction()


4. 放棄事務
void abortTransaction()

******************************************************************************************************

---------------------數據有序
單分區内，有序
多分区，分区与分区间无序

1. 如果没有开启幂等性:
  max.in.flight.requests.per.connection  需要设置为1

2. 开启了幂等性:
max.in.flight.requests.per.connection  需要设置<=5



----------數據亂序
每個broker最多可以緩存5個請求(無應答請求)

// ✅ 示例：Kafka 保证同 key 消息有序发送
// 前提：Kafka 已启动，topic 名为 "order-events"

import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class OrderedProducer {

    public static void main(String[] args) {
        String topic = "order-events";

        // Kafka producer 配置
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        // ✅ 幂等性 + 顺序配置
        props.put(ProducerConfig.ACKS_CONFIG, "all");
        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, "true");
        props.put(ProducerConfig.RETRIES_CONFIG, "3");

        //顺序配置
        props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, "1");

        KafkaProducer<String, String> producer = new KafkaProducer<>(props);

        // 模拟按订单 ID（作为 key）顺序发送 5 条事件
        String orderId = "ORDER-1001";

        for (int i = 1; i <= 5; i++) {
            String message = "Order step " + i;
            ProducerRecord<String, String> record = new ProducerRecord<>(topic, orderId, message);

            producer.send(record, (metadata, exception) -> {
                if (exception == null) {
                    System.out.printf("✅ Sent: key=%s, value=%s, partition=%d, offset=%d%n",
                            record.key(), record.value(), metadata.partition(), metadata.offset());
                } else {
                    exception.printStackTrace();
                }
            });

            try {
                Thread.sleep(200); // 模拟间隔发送
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }

        producer.flush();
        producer.close();
    }
}



             

------------集群脚本:  kafka-topics.sh----------------------------

-----bootstrap-server<String server to connect> 連接kafka broler主機名稱和端口號

-----topic <topic名稱> 找到要操作的topic名稱


-----create   創建主題

------delete  刪除

------alter   修改

-----list     查看所有主題


----describe:查看topic詳情信息

---partitions  指定設置topic分區

---replication-facotr: 指定設置分區副本

---config<String:name=value> 更新系統默認的配置


---查看當前服務器中所有topic:
bin/kafka-topics.sh --bootstrap-server 【kafka100:9092，kafka101:9092，kafka103:9092】 --list


---創建first topic:
 bin/kafka-topics.sh --bootstrap-server kafka100:9092 --topic first --create --partitions 1 --replication-factor 1

【有幾臺服務器Broker就能創建幾個副本replication-factor！！！！！】

----查看first的詳細信息: 
bin/kafka-topics.sh --bootstrap-server kafka100:9092 --topic test-topic --describe

----修改topic
【partitions只能增加，不能減少!!!!!!!】
bin/kafka-topics.sh --bootstrap-server kafka100:9092 --topic first --alter --partitions 3


---------------------消費者: kafka-console-consumer.sh-------------------
消費生產者在主題中生產的數據:
bin/kafka-console-consumer.sh  --bootstrap-server 【kafka100:9092，kafka101:9092，kafka103:9092】 --topic first

bin/kafka-console-consumer.sh  
    --bootstrap-server 【kafka100:9092，kafka101:9092，kafka103:9092】 
    --topic first
    --from beginning
-------------------------------------------------------------------------------------



請檢查 Kafka 服務端（192.168.10.100）的 server.properties 配置：
cat /path/to/kafka/config/server.properties | grep listeners


listeners=PLAINTEXT://0.0.0.0:9092
advertised.listeners=PLAINTEXT://192.168.10.100:9092


-----------------------------------------Kafka Broker-------------------------------------------------

zookeeper中的服务端存储的kafka信息:

1. brokers
ls /kafka/brokers/ids         记录有哪些brokers

 get /kafka/brokers/topics/test-topic/partitions/0/state   记录谁知leader,有哪些服务器可用
{"controller_epoch":1,"leader":0,"version":1,"leader_epoch":0,"isr":[0]}


2./kafka/controller  : controller辅助选举leader
get /kafka/controller
{"version":2,"brokerid":0,"timestamp":"1747916646313","kraftControllerEpoch":-1}


节点服役(添加broker)和退役!!!!!!!!!!!!!!!!!----------------------------------------------------------

1. 创建文件 vim topics-to-move.json

{
  "topics": [
     {"topic": "test-topic"}
  ],
  "version":1
}

2.生成一个负载均衡的计划
bin/kafka-reassign-partitions.sh  --bootstrap-server localhost:9092  --topics-to-move-json-file  topics-to-move.json
 -- broker-list "0,1,2,3" --generate




退役: 将该节点存储的所有数据移到其它节点上，然后将该节点关闭

启动停止: 先停止kafka,  再停止zk
-daemon 参数表示后台运行 Kafka（非阻塞）

ssh $i ... 会远程登录服务器执行命令（需配置好免密 SSH）

脚本：
#!/bin/bash

KAFKA_HOME=/opt/kafka  # 你可以根据你的 Kafka 安装目录修改这个路径

case $1 in
"start")
    echo "➡ Starting Kafka cluster..."
    for i in broker1 broker2 broker3
    do
        echo "Starting Kafka on $i..."
        ssh $i "$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties"
    done
    ;;
"stop")
    echo " Stopping Kafka cluster..."
    for i in broker1 broker2 broker3
    do
        echo "Stopping Kafka on $i..."
        ssh $i "$KAFKA_HOME/bin/kafka-server-stop.sh"
    done
    ;;
*)
    echo "Usage: $0 {start|stop}"
    ;;
esac


chmod +x kafka-cluster.sh
./kafka-cluster.sh start    # 启动整个 Kafka 集群
./kafka-cluster.sh stop     # 停止整个 Kafka 集群


-----------------------------------------Kafka副本： 提高数据可靠性----------------------------------------------------------------------

Leader  Follower: Kafka生产者只会把数据发送到Leader, Follower找Leader进行数据同步

AR(Assigned Replicas) = ISR(正常工作和Leader保持同步的Follower集合) + OSR(与Leader同步时，超时过多的副本)

如果Follower长时间未向Leader发送信息你或者同步数据，会被踢出ISR,进入OSR

该时间阈值: replica.lag.time.max.ms  = 30s

LEO(Log End Offset) : 每一个副本的最后一个offset
HW(High Watermark): 所有副本中最小的LEO


手动调整分区副本存储 ：将所有的副本都指定存储在最好的服务器broker0和broker1中
1. 创建topic test, 指定4个partitions
kafka-topics.sh --bootstrap-server localhost:9092 --create --topic test  --partitions 4  --replication-factor 2

2. 创建副本存储计划(所有副本指定存储在0，1)
increase-replication-factor.json

{
 "version":1,
 "partitions":[
     {"topic":"test","partition":0,"replicas":[0，1]},
     {"topic":"test","partition":1,"replicas":[0，1]},
     {"topic":"test","partition":2,"replicas":[0，1]},
     {"topic":"test","partition":2,"replicas":[0，1]}

 ]
}

3.执行
kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file  increase-replication-factor.json
--execute


4.验证
kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file  increase-replication-factor.json
--execute --verify


5.查看
kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic test

----------------Leader Partition 负载均衡--------------------------------------
auto.leader.rebalance.enable: true(生成环境中不开启)


-------------------------增加副本保证数据更多备份-----------------------
1. 创建topic test, 指定4个partitions
kafka-topics.sh --bootstrap-server localhost:9092 --create --topic test  --partitions 4  --replication-factor 1(创建一个副本)

2. 修改副本，添加一个实现两个副本(无法通过命令行直接实现，必须通过副本存储计划来实现)
increase-replication-factor.json

{
 "version":1,
 "partitions":[
     {"topic":"test","partition":0,"replicas":[0，1，2]},//添加一个实现两个副本
     {"topic":"test","partition":1,"replicas":[0，1，2]},
     {"topic":"test","partition":2,"replicas":[0，1，2]},
     {"topic":"test","partition":2,"replicas":[0，1，2]}

 ]
}

kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file  increase-replication-factor.json
--execute

---------------------------------文件存储机制-----------------------------------------------------
一个Topic test有100T的数据
希望分散到Partition0,Partition1,Partition2
每个分区对应多个Segment方式存储(1G) 包含.log,  .index偏移量索引文件  .timeindex时间索引文件（七天后删除日志）
该文件夹的命名规则:topic名称+分区序号

用命令行查看index和log信息
kafka-run-class.sh kafka.tools.DumpLogSegments --files /00000000000.index

[ kafka使用稀疏索引(sparse index)的方式： 在log中记录4KB的文件， index中才会记录一条 ]

【Kafka 稀疏索引的原理】
Kafka 的每个 log segment（日志段） 文件会配套有两个文件：

.log：实际的数据文件，记录消息内容

.index：稀疏索引文件，用于从偏移量快速定位 .log 文件的物理位置

.timeindex：时间索引文件（用于时间戳查找）

【什么是稀疏索引？】
Kafka 的 .index 文件不是为每条消息都建立索引，而是每隔一定字节数在 .log 文件中记录一个偏移量及其对应的物理位置（byte offset）。
这就是所谓的 稀疏索引（Sparse Index）。

举例说明：

Kafka 的默认设置是每 4KB 的日志数据写入 .log 文件时，就在 .index 文件中记录一条索引。

这意味着，.index 文件的大小远小于 .log 文件，显著降低了内存与磁盘的使用量。

你可以通过如下配置调整稀疏索引密度（不建议随意更改）：
log.index.interval.bytes=4096


---------------------------文件清除策略----------------------------------
log.retention.hours  最低优先级  默认7天

log.retention.minutes:  优先级大于log.retention.hours

log.retention.ms   最高优先级毫秒  -1 -1代表没有时间设置

delete | compact
log.cleanup.policy = delete(默认设置)

compact: compact保留每个key最新的数据

--------------------高效读写数据！！！！！！！--------------------------------------
1. Kafka本身是分布式集群，可以采用分区技术，并行度高

2. 稀疏索引，可以快速定位要消费的数据

3. 顺序写磁盘

4. 零拷贝， 页缓存（linux系统）: 因为Kafka在应用层端完全不处理数据

------------------------------消费者(消费者组)------------------------------------------------------

客户端对象:  每批次拉取的最小字节数 1个字节
           如果每批次拉取的最小字节数没有达到，拉取超时时间500ms
           最大拉取字节数上线 50m
           个数: 500条


pull(拉)： consumer采用从broker中主动拉取数据。


每个分区的数据只能被一个消费者组中的一个消费者消费！！！！！！！！！！！！

offset: 消费的位置

push(推)

消费者组: 由多个消费者组成，所有的消费者的groupId相同
         消费者组内每一个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费

消费者组其实是逻辑上的一个订阅者


四种主流的分区分配策略:
  Range  \     RoundRobin  \   Sticky  \   CooperativeSticky

  7个partitions   3个consumer

  range: 0 1 2   2对分区数进行除模
          3 4
          5 6
再平衡：  45秒之内，全部给一个消费者，45秒之后再重启，从新分配

RoundRobin: 把所有的partition和所有的consumer都列出来，按照hashcode进行排序，最后通过轮询三亚办法来分配partition到各个消费者
0 3 6
1 4
2 5

例如 consumer1： 消费partition0,
consumer2： 消费partition1,
consumer3： 消费partition2,
consumer1： 消费partition3,.........

------------------------------------------------------------------------------------------------------

Sticky: 随机并且尽量均匀 2 2 3



------------------------------------------------------------------------------------------------
offset 维护在系统主题当中!!!!!!!!!!!!!!
offset:在_consumer_offsets主题里采用key和value的方式存储数据
key=group.id+topic+分区号

------------手动提交offset---------------------------
commitSync(同步提交): 会阻塞当前线程，一直到提交成功，并且会自动失败重试


commitAsync(异步提交)：没有失败重试机制，有可能提交失败



按照指定时间消费


漏消费和重复消费:  消费者事务!!!!!!!!!!

我们需要将kafka的 offset保持到支持事务的自定义介质（MySQL）

----生產者提高吞吐量:linger.ms: 默認爲0ms,只要有消息就立刻發送

修改 batch.size： 批次大小，默認16k
    linger.ms: 等待時間，修改為5-100ms(影响数据延时)
    compression.tye: 壓縮snappy
    RecordAccumulator: 緩衝區大小，修改爲64m

消费者如何提高吞吐量:
1. 增加Topic的分区数，同时提升消费者组的消费者数量

2. 提高每批次拉去的数量

-----------------------------------Kafka-Eagle监控-----------------------------------------------


--------------SpringBoot-------------------------------------

SpringBoot(生产者) ==》 Kafka  =====> SpringBoot(消费者)






